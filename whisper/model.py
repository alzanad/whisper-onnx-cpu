import io
import os
from dataclasses import dataclass
from typing import List, Dict, Tuple
import numpy as np
import requests
import psutil
import onnx
from onnx.serialization import ProtoSerializer
import onnxruntime as ort
from whisper.decoding import detect_language as detect_language_function, decode as decode_function
from whisper.utils import onnx_dtype_to_np_dtype_convert
import json
from pathlib import Path


def model_download(name: str, onnx_file_save_path: str = '.') -> bytes:
    """ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ù†Ù…ÙˆØ°Ø¬ ONNX Ù…Ù† Ø§Ù„Ø®Ø§Ø¯Ù…"""
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø³ÙƒØ±ÙŠØ¨Øª
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    config = load_config_for_model(current_dir)
    models_dir = config.get("models_directory", "whisper-models")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø³Ø§Ø±Ø§Ù‹
    if '/' in name or '\\' in name:
        model_name = os.path.basename(name)
        model_dir = os.path.dirname(name)
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ù†Ø³Ø¨ÙŠØ§Ù‹ØŒ Ø§Ø¬Ø¹Ù„Ù‡ Ù…Ø·Ù„Ù‚Ø§Ù‹
        if not os.path.isabs(model_dir):
            model_dir = os.path.join(current_dir, model_dir)
        onnx_file_path = os.path.join(model_dir, f"{model_name}_11.onnx")
    else:
        model_name = name
        if onnx_file_save_path == '.':
            # Ø§Ø³ØªØ®Ø¯Ù… Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
            if not os.path.isabs(models_dir):
                onnx_file_save_path = os.path.join(current_dir, models_dir)
            else:
                onnx_file_save_path = models_dir
        elif not os.path.isabs(onnx_file_save_path):
            onnx_file_save_path = os.path.join(current_dir, onnx_file_save_path)
        onnx_file_path = os.path.join(onnx_file_save_path, f'{name}_11.onnx')
    
    if not os.path.exists(onnx_file_path):
        # Ø¥Ø°Ø§ Ù„Ù… ÙŠØ¬Ø¯ Ø§Ù„Ù…Ù„ÙØŒ Ø£Ø·Ø¨Ø¹ Ø±Ø³Ø§Ù„Ø© Ø®Ø·Ø£ ÙˆØªÙˆÙ‚Ù
        print(f"âŒ Ø®Ø·Ø£: Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {onnx_file_path}")
        print(f"ðŸ“¥ ÙŠØ¬Ø¨ ØªÙ†Ø²ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙˆØ¶Ø¹Ù‡ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨")
        print(f"ðŸ”— Ø±Ø§Ø¨Ø· Ø§Ù„ØªÙ†Ø²ÙŠÙ„: https://s3.ap-northeast-2.wasabisys.com/pinto-model-zoo/381_Whisper/onnx/{model_name}_11.onnx")
        exit(1)
    
    # Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
    serializer: ProtoSerializer = onnx._get_serializer(fmt='protobuf')
    onnx_graph: onnx.ModelProto = onnx.load(onnx_file_path)
    onnx_serialized_graph = serializer.serialize_proto(proto=onnx_graph)
    
    return onnx_serialized_graph

def load_config_for_model(current_dir):
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬"""
    # Ø§Ù„Ø¨Ø­Ø« Ø£ÙˆÙ„Ø§Ù‹ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠØŒ Ø«Ù… ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø£Ø¨
    config_path = Path(current_dir) / "config.json"
    if not config_path.exists():
        config_path = Path(current_dir).parent / "config.json"
    
    if config_path.exists():
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, IOError):
            pass
    
    # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    return {
        "models_directory": "whisper-models",
        "audio_directory": "audio",
        "output_directory": "output"
    }

def load_model(name: str):
    """
    Load a Whisper ASR model

    Parameters
    ----------
    name : str
        one of the official model names listed by `whisper.available_models()`, or
        path to a model (e.g., "whisper-models/tiny.en")

    Returns
    -------
    model : Whisper
        The Whisper ASR model instance
    """
    # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ù„Ø³ÙƒØ±ÙŠØ¨Øª
    current_dir = os.path.dirname(os.path.abspath(__file__))
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
    config = load_config_for_model(current_dir)
    models_dir = config.get("models_directory", "whisper-models")
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ø£Ùˆ Ø§Ù„Ø§Ø³Ù…
    if '/' in name or '\\' in name:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø³Ø§Ø±Ø§Ù‹ØŒ Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ø³Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Ø¢Ø®Ø± Ø¬Ø²Ø¡
        model_name = os.path.basename(name)
        model_dir = os.path.dirname(name)
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ø³Ø§Ø± Ù†Ø³Ø¨ÙŠØ§Ù‹ØŒ Ø§Ø¬Ø¹Ù„Ù‡ Ù…Ø·Ù„Ù‚Ø§Ù‹
        if not os.path.isabs(model_dir):
            model_dir = os.path.join(current_dir, model_dir)
        encoder_path = os.path.join(model_dir, f"{model_name}_encoder_11.onnx")
        decoder_path = os.path.join(model_dir, f"{model_name}_decoder_11.onnx")
    else:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù…Ø§Ù‹ ÙÙ‚Ø·ØŒ Ø§Ø¨Ø­Ø« ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø£ÙˆÙ„Ø§Ù‹
        model_name = name
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ù…Ù† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
        if not os.path.isabs(models_dir):
            models_full_path = os.path.join(current_dir, models_dir)
        else:
            models_full_path = models_dir
            
        encoder_path = os.path.join(models_full_path, f"{name}_encoder_11.onnx")
        decoder_path = os.path.join(models_full_path, f"{name}_decoder_11.onnx")
        
        # Ø¥Ø°Ø§ Ù„Ù… ØªÙˆØ¬Ø¯ ÙÙŠ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§ØªØŒ Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
        if not (os.path.exists(encoder_path) and os.path.exists(decoder_path)):
            encoder_path = os.path.join(current_dir, f"{name}_encoder_11.onnx")
            decoder_path = os.path.join(current_dir, f"{name}_decoder_11.onnx")
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ù„ÙÙŠ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ÙŠÙ†
    if not os.path.exists(encoder_path) or not os.path.exists(decoder_path):
        print(f"âŒ Ø®Ø·Ø£: Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ '{name}' ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
        print(f"ðŸ“ Ù…Ù„ÙØ§Øª Ù…Ø·Ù„ÙˆØ¨Ø©:")
        print(f"   - {encoder_path}")
        print(f"   - {decoder_path}")
        print(f"ðŸ“¥ ÙŠØ¬Ø¨ ØªÙ†Ø²ÙŠÙ„ Ù‡Ø°ÙŠÙ† Ø§Ù„Ù…Ù„ÙÙŠÙ† ÙˆÙˆØ¶Ø¹Ù‡Ù…Ø§ ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…Ù†Ø§Ø³Ø¨")
        print(f"ðŸ”— Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙ†Ø²ÙŠÙ„:")
        print(f"   - https://s3.ap-northeast-2.wasabisys.com/pinto-model-zoo/381_Whisper/onnx/{model_name}_encoder_11.onnx")
        print(f"   - https://s3.ap-northeast-2.wasabisys.com/pinto-model-zoo/381_Whisper/onnx/{model_name}_decoder_11.onnx")
        exit(1)
    
    # ØªØ­Ø¯ÙŠØ¯ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³Ù…
    dims_config = _get_model_dimensions(model_name)
    if not dims_config:
        print(f"âŒ Ø®Ø·Ø£: Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… '{model_name}'")
        print(f"ðŸ“‹ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©: {available_models()}")
        exit(1)
    
    dims = ModelDimensions(**dims_config)
    model = Whisper(dims=dims, model_name=model_name)
    return model

def _get_model_dimensions(name: str) -> dict:
    """Ø¥Ø±Ø¬Ø§Ø¹ Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø­Ø³Ø¨ Ø§Ù„Ø§Ø³Ù…"""
    model_configs = {
        "tiny": {'n_mels': 80, 'n_vocab': 51865, 'n_audio_ctx': 1500, 'n_audio_state': 384, 'n_audio_head': 6, 'n_audio_layer': 4, 'n_text_ctx': 448, 'n_text_state': 384, 'n_text_head': 6, 'n_text_layer': 4},
        "tiny.en": {'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 384, 'n_audio_head': 6, 'n_audio_layer': 4, 'n_text_ctx': 448, 'n_text_state': 384, 'n_text_head': 6, 'n_text_layer': 4},
        "base": {'n_mels': 80, 'n_vocab': 51865, 'n_audio_ctx': 1500, 'n_audio_state': 512, 'n_audio_head': 8, 'n_audio_layer': 6, 'n_text_ctx': 448, 'n_text_state': 512, 'n_text_head': 8, 'n_text_layer': 6},
        "base.en": {'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 512, 'n_audio_head': 8, 'n_audio_layer': 6, 'n_text_ctx': 448, 'n_text_state': 512, 'n_text_head': 8, 'n_text_layer': 6},
        "small": {'n_mels': 80, 'n_vocab': 51865, 'n_audio_ctx': 1500, 'n_audio_state': 768, 'n_audio_head': 12, 'n_audio_layer': 12, 'n_text_ctx': 448, 'n_text_state': 768, 'n_text_head': 12, 'n_text_layer': 12},
        "small.en": {'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 768, 'n_audio_head': 12, 'n_audio_layer': 12, 'n_text_ctx': 448, 'n_text_state': 768, 'n_text_head': 12, 'n_text_layer': 12},
        "medium": {'n_mels': 80, 'n_vocab': 51865, 'n_audio_ctx': 1500, 'n_audio_state': 1024, 'n_audio_head': 16, 'n_audio_layer': 24, 'n_text_ctx': 448, 'n_text_state': 1024, 'n_text_head': 16, 'n_text_layer': 24},
        "medium.en": {'n_mels': 80, 'n_vocab': 51864, 'n_audio_ctx': 1500, 'n_audio_state': 1024, 'n_audio_head': 16, 'n_audio_layer': 24, 'n_text_ctx': 448, 'n_text_state': 1024, 'n_text_head': 16, 'n_text_layer': 24}
    }
    return model_configs.get(name)

def available_models() -> List[str]:
    """Returns the names of available models"""
    return ["tiny.en", "tiny", "base.en", "base", "small.en", "small", "medium.en", "medium"]

@dataclass
class ModelDimensions:
    n_mels: int
    n_audio_ctx: int
    n_audio_state: int
    n_audio_head: int
    n_audio_layer: int
    n_vocab: int
    n_text_ctx: int
    n_text_state: int
    n_text_head: int
    n_text_layer: int


class OnnxAudioEncoder():
    def __init__(
        self,
        model: str,
    ):
        super().__init__()

        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = psutil.cpu_count(logical=True) - 1
        self.sess = \
            ort.InferenceSession(
                path_or_bytes=model_download(name=f'{model}_encoder'),
                sess_options=sess_options,
                providers=[
                    'CPUExecutionProvider'
                ],
            )
        self.inputs = {
            input.name: onnx_dtype_to_np_dtype_convert(input.type) \
                for input in self.sess.get_inputs()
        }

    def __call__(
        self,
        mel: np.ndarray
    ) -> np.ndarray:
        result: np.ndarray = \
            self.sess.run(
                output_names=[
                    "output",
                ],
                input_feed={
                    "mel": mel.astype(self.inputs["mel"]),
                }
            )[0]
        return result


class OnnxTextDecoder():
    def __init__(
        self,
        model: str,
    ):
        super().__init__()

        sess_options = ort.SessionOptions()
        sess_options.intra_op_num_threads = psutil.cpu_count(logical=True) - 1
        self.sess = \
            ort.InferenceSession(
                path_or_bytes=model_download(name=f'{model}_decoder'),
                sess_options=sess_options,
                providers=[
                    'CPUExecutionProvider'
                ],
            )
        self.inputs = {
            input.name: onnx_dtype_to_np_dtype_convert(input.type) \
                for input in self.sess.get_inputs()
        }

    def __call__(
        self,
        x: np.ndarray,
        xa: np.ndarray,
        kv_cache: np.ndarray,
        offset: int,
    ) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
        outputs = \
            self.sess.run(
                output_names=[
                    "logits",
                    "output_kv_cache",
                    "cross_attention_qks",
                ],
                input_feed={
                    "tokens": x.astype(self.inputs["tokens"]),
                    "audio_features": xa.astype(self.inputs["audio_features"]),
                    "kv_cache": kv_cache.astype(self.inputs["kv_cache"]),
                    "offset": np.array([offset], dtype=self.inputs["offset"]),
                }
            )
        logits: np.ndarray = outputs[0]
        output_kv_cache: np.ndarray = outputs[1]
        cross_attention_qks: np.ndarray = outputs[2]
        return logits.astype(np.float32), output_kv_cache.astype(np.float32)


class Whisper():
    def __init__(
        self,
        dims: ModelDimensions,
        model_name: str,
    ):
        super().__init__()
        self.model_name = model_name
        self.dims = dims
        self.encoder = OnnxAudioEncoder(model=model_name)
        self.decoder = OnnxTextDecoder(model=model_name)

    def embed_audio(
        self,
        mel: np.ndarray,
    ):
        return self.encoder(mel)

    def logits(
        self,
        tokens: np.ndarray,
        audio_features: np.ndarray,
    ):
        kv_cache = self.new_kv_cache(tokens.shape[0], tokens.shape[-1])
        output, _ = self.decoder(tokens, audio_features, kv_cache=kv_cache, offset=0)
        return output

    def __call__(
        self,
        mel: np.ndarray,
        tokens: np.ndarray,
    ) -> Dict[str, np.ndarray]:
        kv_cache = self.new_kv_cache(tokens.shape[0], tokens.shape[-1])
        output, _ = self.decoder(tokens, self.encoder(mel), kv_cache=kv_cache, offset=0)
        return output

    @property
    def is_multilingual(self):
        return self.dims.n_vocab == 51865

    def new_kv_cache(
        self,
        n_group: int,
        length: int,
    ):
        if self.model_name == "tiny.en" or self.model_name == "tiny":
            size = [8, n_group, length, 384]
        elif self.model_name == "base.en" or self.model_name == "base":
            size = [12, n_group, length, 512]
        elif self.model_name == "small.en" or self.model_name == "small":
            size = [24, n_group, length, 768]
        elif self.model_name == "medium.en" or self.model_name == "medium":
            size = [48, n_group, length, 1024]
        else:
            raise ValueError(f"Unsupported model type: {self.type}")
        return np.zeros(size, dtype=np.float32)

    detect_language = detect_language_function
    # transcribe = transcribe_function
    decode = decode_function
